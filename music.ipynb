{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "music.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "h01iJ2cDuH_w"
      },
      "source": [
        "import os\n",
        "import librosa, librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MswplmCGue5G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7d251328-5afe-4f90-a38f-1170296215c7"
      },
      "source": [
        "for root, folders, files in os.walk('/content/drive/MyDrive/Python Project/sound'):\n",
        "        # going into sound folder in drive\n",
        "    for folder in folders:\n",
        "        os.makedirs(f'/content/img_data/{folder}',0o666)     #creating folder\n",
        "        print(f'Processing {folder}')   #prefix f is for formatting\n",
        "        for _root, _folders, _files in os.walk(f'/content/drive/MyDrive/Python Project/sound/{folder}'):\n",
        "                #going into every folders of sound\n",
        "            for file in _files:\n",
        "                  #going into every files of the folders in sound\n",
        "                signal, sr = librosa.load(f'/content/drive/MyDrive/Python Project/sound/{folder}/{file}', sr=22050)\n",
        "                size = signal.shape[0]\n",
        "                start = 0\n",
        "                end = start + (size//5) #dividing the sound into 5 parts for more accuracy\n",
        "                for i in range(5):\n",
        "                    part_of_signal = signal[start:end]\n",
        "                    mfcc = librosa.feature.mfcc(part_of_signal,\n",
        "                                n_fft=2048,\n",
        "                                hop_length=512,\n",
        "                                n_mfcc=13)\n",
        "                    librosa.display.specshow(mfcc, sr=sr, hop_length=512)\n",
        "                    plt.savefig(f'/content/img_data/{folder}/{file[:-4] +\"_\"+ str(i)}.png')\n",
        "                    start = end\n",
        "                    end = start + (size//5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing normal\n",
            "Processing wheezes\n",
            "Processing pleuralrub\n",
            "Processing crackle\n",
            "Processing stridor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtlZdFar5Kk_",
        "outputId": "06f99ab5-80fd-4fd5-89fc-425a4c563357"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJDieOERFvw5"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pqU4v2PGIMF"
      },
      "source": [
        "training_set = ImageDataGenerator(rescale=1./255)\n",
        "test_set = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4QVRsIwGKlG"
      },
      "source": [
        "! pip install split-folders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtpNGMC6GR3m"
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio('img_data', output=\"out\", seed=1337, ratio=(.9, .1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JyTzI5aGUw9"
      },
      "source": [
        "training_data = training_set.flow_from_directory(\n",
        "        '/content/out/train',\n",
        "        batch_size=1,\n",
        "        target_size=(128, 128))\n",
        "\n",
        "val_data = test_set.flow_from_directory(\n",
        "        '/content/out/val',\n",
        "        batch_size=1,\n",
        "        target_size=(128, 128))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGUdAF3VTsEB"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3),activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(64, (3,3),activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Conv2D(64, (3,3),activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.15))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(3e-4),\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6vYSjIe_hqY"
      },
      "source": [
        "log_dir = \"logs/fit/\" + \"MODEL_14\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model.fit(training_data,\n",
        "          validation_data=val_data,epochs=50,\n",
        "          callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgwb0cDWpT6-"
      },
      "source": [
        "model.evaluate(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fk5aCfkpU4x"
      },
      "source": [
        "things = model.predict(val_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozFFIsxCpXq3"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8ftJ6ufpbh7"
      },
      "source": [
        "pred = np.argmax(things,axis=1)\n",
        "val_data.class_indices\n",
        "classes = { j:i for i,j in val_data.class_indices.items()}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbcBHNSQpkSa"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDbx-PxxplB5"
      },
      "source": [
        "things = pd.DataFrame({'FILES':val_data.filenames,'PRED':[classes[x] for x in pred]})\n",
        "things\n",
        "# ! rm -r img_data/.ipynb_checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Of59W6C5qNaY"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5Wwc8mzqY0K"
      },
      "source": [
        "model.save('MODEL.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py-JuqUiqjjA"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import math\n",
        "class find_ans :\n",
        "  def __init__(self,model_name):\n",
        "    self.model = load_model(model_name)\n",
        "    self.dic = {0:\"crackle\",1:\"normal\",2:\"pleuralrub\",3:\"stridor\",4:\"wheezes\"}  \n",
        "  def audio_to_spec(self,aud) :\n",
        "    signal, sr = librosa.load(aud, sr=22050)\n",
        "    size = signal.shape[0]\n",
        "    start = 0\n",
        "    end = start + math.floor(size/5)\n",
        "    for i in range(5):\n",
        "        part_of_signal = signal[start:end]\n",
        "        mfcc = librosa.feature.mfcc(part_of_signal,\n",
        "                    n_fft=2048,\n",
        "                    hop_length=512,\n",
        "                    n_mfcc=13)\n",
        "        librosa.display.specshow(mfcc, sr=sr, hop_length=512)\n",
        "        plt.savefig(f\"test_img_{i}.png\")\n",
        "        plt.axis('off')\n",
        "        plt.clf()\n",
        "        start = end\n",
        "        end = start + math.floor(size/5)\n",
        "  def predict(self,aud):\n",
        "    self.audio_to_spec(aud)\n",
        "    results = []\n",
        "    for i in range(5):\n",
        "      matrix = image.load_img(f\"test_img_{i}.png\",target_size=(128,128))\n",
        "      matrix = image.img_to_array(matrix) \n",
        "      pred = self._predict(matrix)\n",
        "      results.append(pred)\n",
        "      from collections import Counter\n",
        "      return Counter(results).most_common()[0][0]\n",
        "    return results\n",
        "  def _predict(self,specgram):\n",
        "    specgram = specgram/255.0\n",
        "    specgram = specgram.reshape(1,specgram.shape[0],specgram.shape[1],specgram.shape[2])\n",
        "    prediction = self.model.predict(specgram)\n",
        "    prediction = np.argmax(prediction)\n",
        "    return self.dic[prediction]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGo70wRRtPFu"
      },
      "source": [
        "obj = find_ans(\"/content/drive/MyDrive/Python Project/real.h5\")\n",
        "obj.predict('/content/drive/MyDrive/Python Project/sound/stridor/ab s1.wav')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}